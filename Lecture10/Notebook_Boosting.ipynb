{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a952ad54-2218-4382-b2eb-d401d349f764",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"../banner.jpg\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65198d8b",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ignaciomsarmiento/BDML_202402/blob/main/Lecture10/Notebook_Boosting.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e57de4",
   "metadata": {},
   "source": [
    "# Tree-Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260d65c5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdab5a6",
   "metadata": {},
   "source": [
    "Let's load the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b75c45",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages(\"pacman\") #run this line if you use Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec986272",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#packages\n",
    "require(\"pacman\")\n",
    "p_load(\"tidyverse\",\"ggplot2\",\"rpart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d5683",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "db<-read.csv(\"https://raw.githubusercontent.com/ignaciomsarmiento/datasets/main/boosting_tree_toy.csv\")\n",
    "head(db)\n",
    "\n",
    "y<-db$y\n",
    "x<-db$x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b8d98",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16de9b17",
   "metadata": {},
   "source": [
    "### Hiperparámetros\n",
    "\n",
    "- $\\lambda$ la tasa a la que aprende, los valores típicos son 0.01 o 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b8eb8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "lambda<-.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803efa12",
   "metadata": {},
   "source": [
    "- Tamaño del árbol. Arboles pocos profundos  funcionan bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a38ab",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "d<-1 #stump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1045170",
   "metadata": {},
   "source": [
    "- Iniciamos fijando $\\hat{f}(x)=0$ y $r_i=y_i$ para todos los $i$ del training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d24b76",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fhat=rep(0,length(y))\n",
    "\n",
    "r=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286152cf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34f0bf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e534be3",
   "metadata": {},
   "source": [
    "Para $m=1,2,...,M$\n",
    "\n",
    " - Ajustamos un árbol $\\hat{f}^m$ con $d$ bifurcaciones ($d+1$ hojas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17ea0a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Primera iteración\n",
    "fit1<-rpart(r ~ x, control = list(maxdepth = d))\n",
    "yhat1<-predict(fit1,newdata=data.frame(x))\n",
    "\n",
    "head(lambda *yhat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30850aef",
   "metadata": {},
   "source": [
    "   - Actualizamos $\\hat{f}(x)$ con una versión \"shrunken\" del nuevo árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b1227",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "f1<-fhat + lambda *yhat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94798b7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(x,y,ylab=\"\",xlab=\"\")\n",
    "lines(x,f1,type=\"s\",col=\"red\",lwd=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db56fad",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "- Actualizamos los residuales\n",
    "  \\begin{align}\n",
    "  r_i\\leftarrow r_i-\\lambda\\hat{f}^m(x)\n",
    "  \\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a625c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "r1<- r - lambda*yhat1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f354c5",
   "metadata": {},
   "source": [
    "El loop vuelve a iniciar, en la iteración 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06427867",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# iteracion 2\n",
    "\n",
    "fit2<-rpart(r1 ~ x, control = list(maxdepth = d))\n",
    "yhat2<-predict(fit2,newdata=data.frame(x))\n",
    "f2<- f1 + lambda *yhat2\n",
    "\n",
    "head(lambda *yhat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d407ef8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(x,y,ylab=\"\",xlab=\"\")\n",
    "lines(x,f2,type=\"s\",col=\"red\",lwd=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57db0c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0b9dd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# En un loop\n",
    "fhat<-rep(0,length(y))\n",
    "\n",
    "r = y\n",
    "\n",
    "YP<-lambda*fhat\n",
    "\n",
    "for(t in 1:500){\n",
    "  fit <- rpart(r~x, control = list(maxdepth = 1))\n",
    "  yhat<- predict(fit,newdata=data.frame(x))\n",
    "  r <-  r - lambda*yhat\n",
    "  YP <-  cbind(YP,lambda*yhat)}\n",
    "\n",
    "head(YP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92224be0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sum(YP[1,c(1,2,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc8e2b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "M<-500\n",
    "\n",
    "fhat<-apply(YP[,1:M],1,sum)\n",
    "\n",
    "plot(x,y,ylab=\"\",xlab=\"\")\n",
    "lines(x,fhat,type=\"s\",col=\"red\",lwd=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a3dcd",
   "metadata": {},
   "source": [
    "## Predicting House Prices\n",
    "\n",
    "\n",
    "$$\n",
    "Precio=f(structural\\,attributes,location,...)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08f3fa",
   "metadata": {},
   "source": [
    "### Ames Data Set\n",
    "\n",
    "The data set contains information from the Ames Assessor’s Office used in computing assessed values for individual residential properties sold in Ames, IA from 2006 to 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d6dcf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p_load(\"modeldata\",\"caret\")\n",
    "\n",
    "data(\"ames\", package = \"modeldata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3997a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dim(ames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b90bab",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(ames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555ba52",
   "metadata": {},
   "source": [
    "The description of the variables can be viewed here: https://jse.amstat.org/v19n3/decock/DataDocumentation.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1732bc",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348bb241",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\hat{f}_{gbm}(x)=\\sum_{m=1}^{M}\\lambda \\hat{f}_{m}(x_{i})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a03ec",
   "metadata": {},
   "source": [
    "- n.trees (# Boosting Iterations) $M$\n",
    "- interaction.depth (Max Tree Depth) $J$\n",
    "- shrinkage (Shrinkage) $\\lambda$\n",
    "- n.minobsinnode (Min. Terminal Node Size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4cc59",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p_load('gbm')\n",
    "\n",
    "\n",
    "grid_gbm<-expand.grid(n.trees=c(200,300,500),\n",
    "                      interaction.depth=c(4,6),\n",
    "                      shrinkage=c(0.001,0.01),\n",
    "                      n.minobsinnode = c(10,30))\n",
    "\n",
    "\n",
    "grid_gbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a71b7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fitControl<-trainControl(method =\"cv\",\n",
    "                         number=5)\n",
    "\n",
    "set.seed(1011)\n",
    "gbm_tree <- train( log(Sale_Price) ~ .,\n",
    "    data=ames,\n",
    "  method = \"gbm\", \n",
    "  trControl = fitControl,\n",
    "  tuneGrid=grid_gbm,\n",
    "  verbose = FALSE\n",
    ")            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9cf31",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gbm_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b12b41-6bb2-4e12-a8a0-875736a58c16",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "min(gbm_tree$results$RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e630439",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0177d",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L} &= \\sum_{i=1}^N L(y_i,\\hat{y}_i) + \\sum_{k=1}^m \\Omega(f_k)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5d218",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p_load('xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade69ca2",
   "metadata": {},
   "source": [
    "Hiper parametros en `R`\n",
    "\n",
    "-  nrounds (# of trees): This parameter is similar to the random forest parameter. It determines the number of trees in the gradient-boosting forest (M). A range I often explore  100 and 1000 trees.\n",
    "\n",
    "- max_depth (Max Tree Depth): The depth of a tree corresponds to how many branches deep each tree is allowed to go (J). A larger depth corresponds to more flexible trees, which can also lead to overfitting. The default tree depth in xgboost is 6, and it is often useful to explore max_depth range of between 4 and 8.\n",
    "\n",
    "- eta (Shrinkage): The eta parameter controls how the boosted tree at a given iteration is merged with the tree in the previous iteration ($\\eta$ in the algorithm). The default value is 0.3, and evaluating a range of effects between 0.01 and 0.5 is often important.\n",
    "\n",
    "- min_child_weight (min obs per node) This parameter refers to the minimum allowable number of observations in each node. The default value is 1. However, this number is quite low, and caution is warranted here, particularly when the max_depth is large. I always set this value to at least ten and often explore ranges between 10 and 50.\n",
    "\n",
    "- gamma (Minimum Loss Reduction) The gamma parameter controls the extent to which changes in the tree structure occur based on changes in the loss function (this is the $\\gamma$ in the equation). The default gamma value is 0.  I often explore 0 and 1\n",
    "\n",
    "- lambda (regularization term on weights) is the $\\lambda$ parameter in the above equation. The default is set to 1.\n",
    "\n",
    "- colsample_bytree (Subsample Ratio of Columns)\n",
    " \n",
    "- subsample (Subsample Percentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9243c4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "grid_xbgoost <- expand.grid(nrounds = c(100,250),\n",
    "                            max_depth = c(2,4), \n",
    "                            eta = c(0.01,0.05), \n",
    "                            gamma = c(0,1), \n",
    "                            min_child_weight = c(10, 25),\n",
    "                            colsample_bytree = c(0.33,0.66),\n",
    "                            subsample = c(0.4,0.8))\n",
    "\n",
    "grid_xbgoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3568c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(1011)\n",
    "Xgboost_tree <- train(log(Sale_Price) ~ .,\n",
    "    data=ames,\n",
    "  method = \"xgbTree\", \n",
    "  trControl = fitControl,\n",
    "  tuneGrid=grid_xbgoost\n",
    ")        \n",
    "\n",
    "Xgboost_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82f989-23c6-45cc-85f8-45000bc623ee",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Xgboost_tree$bestTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d36149c-7e63-4d19-902d-88325f4a8288",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "min(Xgboost_tree$results$RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2963f23",
   "metadata": {},
   "source": [
    "It’s important to note that there is never a single optimal tuning parameter choice for all (or even most) settings. In fact, the choice of a given tuning parameter often has important effects on the optimal value of other tuning parameters. There are usually important tradeoffs to consider between tuning parameter values. For example, in the context of XGBoost, a high value of `min_child_weight` may require a lower `eta` or `max_depth` value. However, this is true for other types of machine learning algorithms."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
