{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35c5565c",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"../banner.jpg\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9fd15",
   "metadata": {},
   "source": [
    "# Aplications\n",
    "\n",
    "\n",
    "-   To illustrate how it works let me use this experiment from the General Social Survey (GSS)\n",
    "\n",
    "-   GSS conducts surveys regular surveys on Americans think feel about different issues\n",
    "\n",
    "-   For decades, scholars studying Americans' support for social welfare spending have noted the special disdain that americans harbor for programs labeled \"welfare\"\n",
    "\n",
    "-   This phenomenon became the subject of sustained experimental inquiry in the mid-1980s, when the GSS included a question-wording experiment in its national survey of adults.\n",
    "\n",
    "\n",
    "-   Respondents in each survey were randomly assigned to one of two questions about public spending.\n",
    "\n",
    "-   *\"too much\" money is spent on assistance to the Poor (treatment) or Welfare (control)*\n",
    "\n",
    "-   Various explanations put forward: stereotypes associated with welfare recipients and poor people, particularly racial stereotypes, and to political orientations such as individualism and conservatism .\n",
    "\n",
    "\n",
    "## Loading packages\n",
    "\n",
    "Let's load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6e377-f598-409d-ab7c-0c61d9f8011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"pacman\") #run this line if you use Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1d4d8",
   "metadata": {
    "include": true,
    "message": false,
    "name": "cran_packages",
    "warning": false
   },
   "outputs": [],
   "source": [
    "set.seed(201911) \n",
    "\n",
    "require(\"pacman\")\n",
    "p_load(\"tidyverse\",# Data wrangling       \n",
    "        \"fBasics\",     # Summary statistics \n",
    "        \"corrplot\",    # Correlations \n",
    "        \"psych\",       # Correlation p-values \n",
    "        \"hdm\",         # High-Dimensional Metrics\n",
    "        \"rpart\",       # Classification and regression trees\n",
    "        \"rpart.plot\",  # Plotting trees \n",
    "        \"car\",         # linear hypothesis testing for causal tree\n",
    "        \"aod\")         # hypothesis testing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf8291",
   "metadata": {},
   "source": [
    "**Non-CRAN packages:** The packages below have not yet been uploaded to CRAN or any other major package repository, but we can grab them from their authors' github webpages. If you don't have these packages installed already, uncomment the relevant line below to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56767771",
   "metadata": {
    "include": true,
    "lines_to_next_cell": 2,
    "message": false,
    "name": "noncran_packages",
    "warning": false
   },
   "outputs": [],
   "source": [
    "# For causal trees (Athey and Imbens, 2016)  version 0.0\n",
    "#library(devtools)    # Install packages from github \n",
    "#install_github(\"susanathey/causalTree\")\n",
    "require(\"causalTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a87d16",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "We will be working with the `welfare` dataset, from \"Modeling Heterogeneous Treatment Effects in Survey Experiments with Baysian Additive Regression Trees\" (Green and Kern, 2012) ).\n",
    "\n",
    "Next, we load in the raw data and perform some data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed633b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# R script for reading data from github repository, set path to where you have the tutorial files saved.\n",
    "df_experiment<-readRDS(url(\"https://github.com/ignaciomsarmiento/datasets/raw/main/welfare.rds\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2c3dd",
   "metadata": {
    "name": "select_dataset"
   },
   "outputs": [],
   "source": [
    "head(df_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b76c3b",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "\n",
    "Let's do some minimal housekeeping. First, we will drop the columns that aren't outcomes, treatments or (pre-treatment) covariates, since we won't be using those.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e28c2",
   "metadata": {
    "name": "drop_irrelevant_cols"
   },
   "outputs": [],
   "source": [
    "covariate_names<- c(\"hrs1\", \"partyid\", \"income\", \"rincome\", \"wrkstat\", \"wrkslf\", \"age\", \"polviews\", \"educ\", \"earnrs\", \"race\", \"marital\", \"sibs\", \"childs\", \"occ80\", \"prestg80\", \"indus80\", \"res16\", \"reg16\", \"mobile16\", \"family16\", \"parborn\", \"maeduc\", \"degree\", \"sex\", \"born\", \"hompop\", \"babies\", \"preteen\", \"teens\", \"adults\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all names\n",
    "all_variables_names <- c(\"Y\", \"W\", covariate_names)\n",
    "df <- df_experiment %>% select(all_of(all_variables_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd1ee0",
   "metadata": {},
   "source": [
    "Next, let's drop any row that has missing values in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ce42b",
   "metadata": {
    "name": "data_cleaning"
   },
   "outputs": [],
   "source": [
    "# Drop rows containing missing values\n",
    "df <- df %>% drop_na()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2259fd09",
   "metadata": {},
   "source": [
    "Some of the methods below don't accept `factor` variables, so let's change their type to `numeric` here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348c978",
   "metadata": {
    "name": "column_renaming"
   },
   "outputs": [],
   "source": [
    "# Converting all columns to numerical and add row id\n",
    "df <- data.frame(lapply(df, function(x) as.numeric(as.character(x))))\n",
    "\n",
    "df <- df %>% mutate_if(is.character,as.numeric)\n",
    "df <- df %>% rowid_to_column( \"ID\")\n",
    "\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e910ef67",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f444d888",
   "metadata": {},
   "source": [
    "## Descriptive statistics\n",
    "\n",
    "It's often useful to begin data analysis by simply looking at simple summary statistics. We use the function `basicStats` from the package `fBasics` to calculate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f4a7a3",
   "metadata": {
    "echo": true,
    "message": false,
    "name": "summary_stats",
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "# Make a data.frame containing summary statistics of interest\n",
    "summ_stats <- fBasics::basicStats(df)\n",
    "summ_stats <- as.data.frame(t(summ_stats))\n",
    "# Rename some of the columns for convenience\n",
    "summ_stats <- summ_stats %>% select(\"Mean\", \"Stdev\", \"Minimum\", \"1. Quartile\", \"Median\",  \"3. Quartile\", \"Maximum\")\n",
    "summ_stats <- summ_stats %>% rename('Lower quartile'= '1. Quartile', 'Upper quartile' ='3. Quartile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09962102",
   "metadata": {
    "message": false,
    "name": "summary_stats_table",
    "results": "asis",
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "summ_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef78043",
   "metadata": {},
   "source": [
    "Presenting pairwise correlations is easy with the `corrplot` function from the `corrplot` package. On the table below, if the (unadjusted) p-value for a pair of variables is less than 0.05, its square is not colored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa073e7a",
   "metadata": {
    "fig.height": 5,
    "fig.width": 5,
    "lines_to_next_cell": 2,
    "name": "cor plot",
    "tags": [
     "remove_input"
    ],
    "warning": false
   },
   "outputs": [],
   "source": [
    "# Note: if the plot looks too cramped, try increasing fig.width and fig.height in the line above\n",
    "pairwise_pvalues <- psych::corr.test(df, df)$p\n",
    "corrplot(cor(df),\n",
    "        type=\"upper\",\n",
    "        tl.col=\"black\",\n",
    "        order=\"hclust\",\n",
    "        tl.cex=1,\n",
    "        addgrid.col = \"black\",\n",
    "        p.mat=pairwise_pvalues,\n",
    "        sig.level=0.05,\n",
    "        number.font=10,\n",
    "        insig=\"blank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5306c88",
   "metadata": {},
   "source": [
    "# PART I: ATE y CATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc201f",
   "metadata": {},
   "source": [
    " *\"too much\" money is spent on assistance to the Poor (treatment) or Welfare (control)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a3fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tapply(df$Y,df$W,mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a10626",
   "metadata": {},
   "source": [
    "- 48% agree that too much money is spent on Welfare\n",
    "- 11% agree that too much money is spent on assistance to the Poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3012f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_in_means <- function(dataset) {\n",
    "  # Filter treatment / control observations, pulls outcome variable as a vector\n",
    "  y1 <- dataset %>% dplyr::filter(W == 1) %>% dplyr::pull(Y) # Outcome in treatment grp\n",
    "  y0 <- dataset %>% dplyr::filter(W == 0) %>% dplyr::pull(Y) # Outcome in control group\n",
    "  \n",
    "  n1 <- sum(df[,\"W\"])     # Number of obs in treatment\n",
    "  n0 <- sum(1 - df[,\"W\"]) # Number of obs in control\n",
    "  \n",
    "  # Difference in means is ATE\n",
    "  tauhat <- mean(y1) - mean(y0)\n",
    "  \n",
    "  # 95% Confidence intervals\n",
    "  se_hat <- sqrt( var(y0)/(n0-1) + var(y1)/(n1-1) )\n",
    "  lower_ci <- tauhat - 1.96 * se_hat\n",
    "  upper_ci <- tauhat + 1.96 * se_hat\n",
    "  \n",
    "  return(c(ATE = tauhat, lower_ci = lower_ci, upper_ci = upper_ci))\n",
    "}\n",
    "\n",
    "tauhat_rct <- difference_in_means(df)\n",
    "tauhat_rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_ate <- lm(Y~W, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmla <- as.formula(paste(\"Y ~ W +\", paste(covariate_names, collapse= \"+\")))\n",
    "ols_cate <- lm(fmla, data=df)\n",
    "stargazer::stargazer(ols_ate,ols_cate,type=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f9d77",
   "metadata": {},
   "source": [
    "# Part II: HTE, Causal Trees\n",
    "\n",
    "\n",
    "\n",
    "-   Some authors consider the interaction between the treatment and attributions, e.g.\n",
    "\n",
    "    -   Federico (2004) examines a complicated three-way interaction between the treatment, education, and racial perceptions.\n",
    "\n",
    "    -   Jacoby (2000) suggests that party and ideology may make some respondents especially receptive to the more specific program (should strong and weak Democrats be treated as separate subgroups or should they be combined?)\n",
    "        \n",
    "Let's see how to analyze the data set selected above for heterogeneous treatment effects.        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da516b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-   We need to proceed in steps\n",
    "\n",
    "-   **Step 1**: Split the dataset. Why? $\\rightarrow$ Athey and Imbens\n",
    "    innovation $\\rightarrow$ **Honesty**\n",
    "        \n",
    "-   **Step 2**: Fit the tree\n",
    "-   **Step 3**: Crossvalidate\n",
    "-   **Step 4**: Predict point estimates (on estimation sample)\n",
    "-   **Step 5**: Compute standard errors\n",
    "-   **Step 6**: Predict point estimates (on test set)        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357b9b3e",
   "metadata": {},
   "source": [
    "Before we start let’s separate a portion of our dataset as a test set. Later we will use this subset to evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fedc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction <- 0.80  # Use train_fraction % of the dataset to train our models\n",
    "\n",
    "df_train <- sample_frac(df, replace=F, size=train_fraction)\n",
    "df_test <- anti_join(df,df_train, by = \"ID\")#need to check on larger datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee827c80",
   "metadata": {},
   "source": [
    "#### Step 1: Split the dataset\n",
    "\n",
    "As we just explained, honesty requires us to separate different subsets of our training data for model selection and prediction.\n",
    "\n",
    "+ `df_split`: the *splitting sample*, used to build the tree\n",
    "+ `df_est`: the *estimation sample*, used to compute the average treatment effect in each leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ad0ad",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "train_test"
   },
   "outputs": [],
   "source": [
    "# Diving the data 40%-40%-20% into splitting, estimation and validation samples\n",
    "split_size <- floor(nrow(df_train) * 0.5)\n",
    "df_split <- sample_n(df_train, replace=FALSE, size=split_size)\n",
    "\n",
    "# Make the splits\n",
    "df_est <- anti_join(df_train,df_split, by =\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290df42c",
   "metadata": {},
   "source": [
    "#### Step 2: Fit the tree\n",
    "\n",
    "Begin by defining a formula containing only the outcome and the covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541762a",
   "metadata": {
    "name": "causal_tree_formula"
   },
   "outputs": [],
   "source": [
    "fmla_ct <- paste(\"factor(Y) ~\", paste(covariate_names, collapse = \" + \"))\n",
    "\n",
    "print('This is our regression model')\n",
    "print( fmla_ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54ce23",
   "metadata": {},
   "source": [
    "Next, we use the `honest.causalTree` function from the `causalTree` package. To ensure that honesty is enabled, the parameters for splitting and cross-validation below should not be changed. However, if your tree is not splitting at all, try decreasing the parameter `minsize` that controls the minimum size of each leaf.\n",
    "\n",
    "For more details on other parameters, please take a look at this extended [documentation](https://github.com/susanathey/causalTree/blob/master/briefintro.pdf) for the `causalTree` paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e564049",
   "metadata": {
    "name": "causal_tree_estimation",
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "ct_unpruned <- honest.causalTree(\n",
    "  formula = fmla_ct,            # Define the model\n",
    "  data = df_split,              # Subset used to create tree structure\n",
    "  est_data = df_est,            # Which data set to use to estimate effects\n",
    "\n",
    "  treatment = df_split$W,       # Splitting sample treatment variable\n",
    "  est_treatment = df_est$W,     # Estimation sample treatment variable\n",
    "\n",
    "  split.Rule = \"CT\",            # Define the splitting option\n",
    "  cv.option = \"TOT\",            # Cross validation options\n",
    "\n",
    "  split.Honest = TRUE,          # Use honesty when splitting\n",
    "  cv.Honest = TRUE,             # Use honesty when performing cross-validation\n",
    "\n",
    "  minsize = 30,                 # Min. number of treatment and control cases in each leaf\n",
    "  HonestSampleSize = nrow(df_est)) # Num obs used in estimation after building the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d5f65",
   "metadata": {},
   "source": [
    "The resulting object will be `rpart` objects, so `rpart` methods for cross-validation and plotting can be used.\n",
    "\n",
    "#### Step 3: Cross-validate\n",
    "\n",
    "We must prune the tree by cross-validation to avoid overfitting. The honest cross-validation method selected above (and recommended) penalizes an estimate of the variance in the treatment effects estimates across leaves, and this estimate is computed using the estimation sample. The `cv.option` selected above ($TOT$) uses an unbiased estimate of the test mean-squared error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb20594",
   "metadata": {
    "lines_to_next_cell": 0,
    "name": "causal_tree_cv"
   },
   "outputs": [],
   "source": [
    "# Table of cross-validated values by tuning parameter.\n",
    "ct_cptable <- as.data.frame(ct_unpruned$cptable)\n",
    "\n",
    "# Obtain optimal complexity parameter to prune tree.\n",
    "selected_cp <- which.min(ct_cptable$xerror)\n",
    "optim_cp_ct <- ct_cptable[selected_cp, \"CP\"]\n",
    "\n",
    "# Prune the tree at optimal complexity parameter.\n",
    "ct_pruned <- prune(tree = ct_unpruned, cp = optim_cp_ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5575713",
   "metadata": {},
   "source": [
    "#### Step 4: Predict point estimates (on estimation sample)\n",
    "\n",
    "To predict the treatment effect on the estimation sample, use the function `predict` as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69f3f4",
   "metadata": {
    "name": "causal_tree_predict_est"
   },
   "outputs": [],
   "source": [
    "tauhat_ct_est <- predict(ct_pruned, newdata = df_est)\n",
    "head(tauhat_ct_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15888eb",
   "metadata": {},
   "source": [
    "#### Step 5: Compute standard errors\n",
    "\n",
    "The `causalTree` package does not compute standard errors by default, but we can compute them using the following trick. First, define $L_{\\ell}$ to indicate assignment to leaf $\\ell$ and consider the following linear model.\n",
    "\n",
    "\\begin{align}\n",
    "Y = \\sum_{\\ell} L_{\\ell}\\alpha_{\\ell} + W \\cdot L_{\\ell} \\beta_{\\ell}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd539ffd",
   "metadata": {
    "name": "causal_tree_se"
   },
   "outputs": [],
   "source": [
    "# Create a factor column 'leaf' indicating leaf assignment\n",
    "num_leaves <- length(unique(tauhat_ct_est))  #There are as many leaves as there are predictions\n",
    "\n",
    "df_est$leaf <- factor(tauhat_ct_est, labels = seq(num_leaves))\n",
    "\n",
    "# Run the regression\n",
    "ols_ct <- lm(as.formula(\"Y ~ 0 + leaf + W:leaf\"), data= df_est) \n",
    "print(as.formula(\"Y ~ 0 + leaf + W:leaf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8625fc6d",
   "metadata": {},
   "source": [
    "The interaction coefficients in this regression recover the average treatment effects in each leaf, since\n",
    "\n",
    "\\begin{align}\n",
    "  E[Y|W=1, L=1] - E[Y|W=0, L=1] = (\\alpha_{1} + \\beta_{1}) - (\\alpha_{1}) = \\beta_{1}\n",
    "\\end{align}\n",
    "\n",
    "Therefore, the standard error around the coefficients is also the standard error around the treatment effects. In the next subsection, we will also use these statistics to test hypothesis about leaf estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753574c7",
   "metadata": {
    "name": "causal_tree_summary"
   },
   "outputs": [],
   "source": [
    "ols_ct_summary <- summary(ols_ct)\n",
    "te_summary <- coef(ols_ct_summary)[(num_leaves+1):(2*num_leaves), c(\"Estimate\", \"Std. Error\")]\n",
    "te_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f9c236",
   "metadata": {},
   "source": [
    "#### Step 6: Predict point estimates (on test set)\n",
    "\n",
    "To predict the treatment effect on a new, entirely unseen data, use the function `predict` as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2b102",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "causal_tree_predict_test"
   },
   "outputs": [],
   "source": [
    "tauhat_ct_test <- predict(ct_pruned, newdata = df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4956325f",
   "metadata": {},
   "source": [
    "### Assessing heterogeneity\n",
    "\n",
    "A natural place to begin is by ploting the (pruned) tree. We can use the `rpart.plot` function from the `rpart.plot` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651254e",
   "metadata": {
    "name": "causal_tree_plot_rpart"
   },
   "outputs": [],
   "source": [
    "rpart.plot(\n",
    "  x = ct_pruned,        # Pruned tree\n",
    "  type = 3,             # Draw separate split labels for the left and right directions\n",
    "  fallen = TRUE,        # Position the leaf nodes at the bottom of the graph\n",
    "  leaf.round = 1,       # Rounding of the corners of the leaf node boxes\n",
    "  extra = 100,          # Display the percentage of observations in the node\n",
    "  branch = 0.1,          # Shape of the branch lines\n",
    "  box.palette = \"RdBu\") # Palette for coloring the node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65023e1e",
   "metadata": {},
   "source": [
    "#### Treatment effect heterogeneity\n",
    "\n",
    "We may want to test the treatment effect is different across leaves. That is, to test the null hypothesis that\n",
    "\n",
    "$$\n",
    " E[Y|W=1, L=1] - E[Y|W=0, L=1] =  E[Y|W=1, L=\\ell] - E[Y|W=0, L=\\ell] \\quad \\text{for all } \\ell > 1\n",
    "$$\n",
    "\n",
    "Following the linear model setup described in Step 5 in the previous subsection, we can use the function `linearHypothesis` from the `car` package to test this hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804afd31",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "causal_tree_test_hypothesis_all_leaves"
   },
   "outputs": [],
   "source": [
    "# Null hypothesis: all leaf values are the same\n",
    "hypothesis <- paste0(\"leaf1:W = leaf\", seq(2, num_leaves), \":W\")\n",
    "ftest <- linearHypothesis(ols_ct, hypothesis, test=\"F\")\n",
    "ftest"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "fig.width,include,error,tags,echo,message,fig.height,results,warning,name,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
