{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a952ad54-2218-4382-b2eb-d401d349f764",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"../banner.jpg\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9642029-7ca0-409a-9b2e-e8423f93a587",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ignaciomsarmiento/BDML_202302/blob/main/Lecture05/Notebook_Ridge.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e57de4",
   "metadata": {},
   "source": [
    "\n",
    "# Regularization: Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a3dcd",
   "metadata": {},
   "source": [
    "## Predicting Wages\n",
    "\n",
    "Our objective today is to construct a model of individual wages\n",
    "\n",
    "$$\n",
    "w = f(X) + u \n",
    "$$\n",
    "\n",
    "where w is the  wage, and X is a matrix that includes potential explanatory variables/predictors. In this problem set, we will focus on a linear model of the form\n",
    "\n",
    "\\begin{align}\n",
    " ln(w) & = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p  + u \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ba2f4",
   "metadata": {},
   "source": [
    "were $ln(w)$ is the logarithm of the wage.\n",
    "\n",
    "To illustrate I'm going to use a sample of the NLSY97. The NLSY97 is  a nationally representative sample of 8,984 men and women born during the years 1980 through 1984 and living in the United States at the time of the initial survey in 1997.  Participants were ages 12 to 16 as of December 31, 1996.  Interviews were conducted annually from 1997 to 2011 and biennially since then.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdab5a6",
   "metadata": {},
   "source": [
    "Let's load the packages and the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6979f85e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#install.packages(\"pacman\") #for google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e94ec2b-ab94-4ec8-8512-e370d2f22a56",
   "metadata": {
    "tags": [
     "remove_cell"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#packages\n",
    "require(\"pacman\")\n",
    "p_load(\"tidyverse\",\"stargazer\")\n",
    "\n",
    "nlsy <- read_csv('https://raw.githubusercontent.com/ignaciomsarmiento/datasets/main/nlsy97.csv')\n",
    "\n",
    "nlsy <- nlsy  %>%   drop_na(educ) #dropea los valores faltantes (NA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d73d77",
   "metadata": {},
   "source": [
    "We want to construct a model that predicts well out of sample, and we have potentially 994 regressors. We are going to regularize this regression using Ridge.\n",
    "\n",
    "## Ridge\n",
    "\n",
    "We first illustrate ridge regression, which can be fit using glmnet() with alpha = 0 and seeks to minimize\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\left( y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij}    \\right) ^ 2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2 .\n",
    "$$\n",
    "\n",
    "Notice that the intercept is not penalized. \n",
    "\n",
    "\n",
    "Ridge penalizes the squares  of the coefficients. As a result, ridge shrinks coefficients toward zero, but not all the way.\n",
    "\n",
    "We are going to use Glmnet. Glmnet is a package that fits generalized linear and similar models via penalized maximum likelihood. The regularization path is computed for the lasso or elastic net penalty at a grid of values (on the log scale) for the regularization parameter lambda. The algorithm is extremely fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5df971",
   "metadata": {},
   "source": [
    "## Glmnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e93ba3",
   "metadata": {},
   "source": [
    "To apply a regularized model we can use the `glmnet::glmnet()` function. The `alpha` parameter tells glmnet to perform a ridge (`alpha` = 0), lasso (`alpha` = 1), or elastic net (0 < `alpha` < 1) model. \n",
    "\n",
    "By default, `glmnet` will do two things that you should be aware of:\n",
    "\n",
    "1. Since regularized methods apply a penalty to the coefficients, we need to ensure our coefficients are on a common scale. If not, then predictors with naturally larger values  will be penalized more than predictors with naturally smaller values. By default, `glmnet` automatically standardizes your features. If you standardize your predictors prior to glmnet you can turn this argument off with `standardize = FALSE`.\n",
    "\n",
    "2. `glmnet` will fit ridge models across a wide range of  $\\lambda$  values, which is illustrated below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48194268",
   "metadata": {},
   "source": [
    "`glmnet` has some drawbacks, the main one is that we need to specify the arguments in terms of matrices and vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5e4bb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p_load(\"glmnet\")\n",
    "\n",
    "#Vector that needs predicting\n",
    "y <- nlsy$lnw_2016\n",
    "\n",
    "\n",
    "# Matrix of predictos (only educ, mother and father's education)\n",
    "X <- as.matrix(nlsy  %>% select(educ,mom_educ,dad_educ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b42d3",
   "metadata": {},
   "source": [
    "Let's run the ridge regression (we need to set the parameter `alpha` to zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876f0c1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ridge <- glmnet(\n",
    "  x = X,\n",
    "  y = y,\n",
    "  alpha = 0 #ridge\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46568ae7",
   "metadata": {},
   "source": [
    "Let's see how  how much the coefficients are penalized for different values of $\\lambda$. Notice none of the coefficients are forced to be zero, although they get close to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7f73c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(ridge, xvar = \"lambda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84285ef",
   "metadata": {},
   "source": [
    "#### All the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bc55f3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Matrix of predictos (all but lnw_2016)\n",
    "X <- as.matrix(nlsy  %>% select(-lnw_2016))\n",
    "\n",
    "ridge <- glmnet(\n",
    "  x = X,\n",
    "  y = y,\n",
    "  alpha = 0 #ridge\n",
    ")\n",
    "\n",
    "plot(ridge, xvar = \"lambda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdff4d",
   "metadata": {},
   "source": [
    "## Scale Equivariance\n",
    "\n",
    "We are going to illustrate the scale problems using just education and afqt scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3311c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Vector that needs predicting\n",
    "y <- nlsy$lnw_2016\n",
    "\n",
    "# Matrix of predictos (only educ and afqt)\n",
    "X <- as.matrix(nlsy  %>% select(educ,afqt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b4287",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "stargazer(data.frame(X),type=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bd6f6",
   "metadata": {},
   "source": [
    "Let's run the ridge regression (we need to set the parameter `alpha` to zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d962d5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ridge <- glmnet(\n",
    "  x = X,\n",
    "  y = y,\n",
    "  alpha = 0, #ridge\n",
    "  lambda=20,\n",
    "  standardize=FALSE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c15e1",
   "metadata": {},
   "source": [
    "Let's see the coefficients we obtained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea487ab0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "coef(ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d1503",
   "metadata": {},
   "source": [
    "Compare to OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58c8e2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ols<-lm(y~X)\n",
    "summary(ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b170493",
   "metadata": {},
   "source": [
    "### What happens if we change the scale for education?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85450b47",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "X[,1]<-X[,1]*1000 #multiply first column by 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a876d2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ridge_1000 <- glmnet(\n",
    "  x = X,\n",
    "  y = y,\n",
    "  alpha = 0, #ridge\n",
    " lambda=20,\n",
    "  standardize=FALSE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42fd8f9-5676-42d6-a61a-b691b570b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(ridge_1000)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fadfa",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "coef(ridge_1000)[2]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe89dc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ols_1000<-lm(y~X)\n",
    "summary(ols_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbc4c9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ols_1000$coefficients[2]*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82f59e",
   "metadata": {},
   "source": [
    "## Penalty selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad989ed",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Matrix of predictos (all but lnw_2016)\n",
    "X <- as.matrix(nlsy  %>% select(-lnw_2016))\n",
    "\n",
    "#Vector that needs predicting\n",
    "y <- nlsy$lnw_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84307874",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ridge <- glmnet(\n",
    "  x = X,\n",
    "  y = y,\n",
    "  alpha = 0 #ridge\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e6e86",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f16225",
   "metadata": {},
   "source": [
    "### Kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd8c38",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "?cv.glmnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fec3977",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cv.ridge <- cv.glmnet(\n",
    "  x = X,\n",
    "  y = y,\n",
    "  alpha = 0 #ridge\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b769ed",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cv.ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31f053",
   "metadata": {},
   "source": [
    "We can plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d2c39",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(cv.ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76033caf",
   "metadata": {},
   "source": [
    "This plots the cross-validation curve (red dotted line) along with upper and lower standard deviation curves\n",
    "along the $\\lambda$ sequence (error bars). \n",
    "\n",
    "Two special values along the $\\lambda$ sequence are indicated by the vertical dotted lines:\n",
    " - lambda.min is the value of $\\lambda$ that gives minimum mean cross-validated error, while \n",
    " - lambda.1se is the value of $\\lambda$ that gives the most regularized model such that the cross-validated error is within one standard error of the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83299a64",
   "metadata": {},
   "source": [
    "We can use the following code to get the value of `lambda.min` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094011c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "log(cv.ridge$lambda.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6937d823",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cv.ridge$lambda.min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca54cd",
   "metadata": {},
   "source": [
    "and the model coefficients at that value of $\\lambda$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9ae5b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "coef(cv.ridge, s = \"lambda.min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a39145b",
   "metadata": {},
   "source": [
    "Predictions can be made based on the fitted cv.glmnet object as well. The code below gives predictions for\n",
    "the new input matrix `newx` at `lambda.min`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a13394",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "predict(cv.ridge, newx = X[1:5,], s = \"lambda.min\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
