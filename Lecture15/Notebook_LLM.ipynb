{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"../banner.jpg\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github//ignaciomsarmiento/BDML_202402/blob/main/Lecture15/Notebook_LLM.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construyamos un GPT desde cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat GPT: Entendiendo los Modelos de Lenguaje y su Funcionamiento Interno\n",
    "\n",
    "Chat GPT es lo que llamamos un **modelo de lenguaje**, ya que se encarga de modelar secuencias de palabras, caracteres o, de forma más general, **tokens**. Su principal habilidad radica en comprender cómo las palabras se relacionan y siguen unas a otras en un idioma, en este caso, el inglés. \n",
    "\n",
    "Desde su perspectiva, lo que realmente hace es **completar secuencias**: tú le proporcionas el inicio de una secuencia y el modelo genera el resto basándose en patrones que ha aprendido durante su entrenamiento. Por esta razón, se clasifica como un modelo de lenguaje.\n",
    "\n",
    "Sin embargo, más allá de esta funcionalidad básica, es importante explorar cómo funciona \"bajo el capó\" Chat GPT, es decir, entender los componentes internos que hacen posible su desempeño. La base de este modelo es una red neuronal que modela la secuencia de palabras, y su funcionamiento se deriva de un artículo científico clave titulado **\"Attention is All You Need\"** publicado en 2017. Este trabajo marcó un antes y un después en la inteligencia artificial al introducir la **arquitectura Transformer**, la piedra angular de sistemas como Chat GPT.\n",
    "\n",
    "<div >\n",
    "<img src = \"figs/transformer.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El término GPT significa **\"Generative Pre-trained Transformer\"** (Transformer Generativo Preentrenado), destacando los tres elementos clave que lo definen:\n",
    "\n",
    "1. **Generative (Generativo):** Es capaz de generar texto de forma autónoma y coherente.\n",
    "2. **Pre-trained (Preentrenado):** Ha sido entrenado previamente con grandes cantidades de datos para entender patrones lingüísticos.\n",
    "3. **Transformer:** Utiliza la arquitectura Transformer, que basa su eficacia en un mecanismo conocido como **atención** para procesar y modelar secuencias de texto con gran precisión.\n",
    "\n",
    "Este tutorial se centrará en desglosar cómo la arquitectura Transformer hace posible que Chat GPT modele las secuencias de lenguaje y produzca respuestas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1061,
     "status": "ok",
     "timestamp": 1732027211815,
     "user": {
      "displayName": "Ignacio Sarmiento",
      "userId": "13389231977385907623"
     },
     "user_tz": 300
    },
    "id": "Bx8J5HhE2QC9"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# read it in to inspect it\n",
    "url = 'https://raw.githubusercontent.com/ignaciomsarmiento/BDML_202402/refs/heads/main/Lecture15/tiny_shakespeare.txt'\n",
    "with urllib.request.urlopen(url) as f:\n",
    "    text = f.read().decode('utf-8')  # Decode the bytes to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXwAy8J0863x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFOcXQ_m83hQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMkzHzG0fJwsYHsEkfOUVmi",
   "gpuType": "T4",
   "mount_file_id": "1JSvwInn9HuYZFFb8qx4-YMTsWPP6RnFB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
